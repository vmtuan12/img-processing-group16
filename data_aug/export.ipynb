{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "CZrxYSvurBTc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y7gZLhZHozxk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import PIL\n",
        "\n",
        "from torchvision.transforms import v2\n",
        "import random\n",
        "\n",
        "import gdown\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and extract dataset"
      ],
      "metadata": {
        "id": "RVLRwudnrNXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"wb_recognition_dataset.zip\"):\n",
        "    !gdown --id 1PdWkZe8Vt6xdsTj8KeqxhAd5Tmx4pyNh\n",
        "else:\n",
        "    print(\"File already exists, skipping download.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QhjU_S7pF8S",
        "outputId": "2ba2a55e-bede-428a-8fcf-a0b52ae78dba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1PdWkZe8Vt6xdsTj8KeqxhAd5Tmx4pyNh\n",
            "From (redirected): https://drive.google.com/uc?id=1PdWkZe8Vt6xdsTj8KeqxhAd5Tmx4pyNh&confirm=t&uuid=8bb7c6ad-570b-438b-91ce-983248a23cd1\n",
            "To: /content/wb_recognition_dataset.zip\n",
            "100% 105M/105M [00:00<00:00, 141MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"wb_recognition_dataset\"):\n",
        "    with zipfile.ZipFile(\"wb_recognition_dataset.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"wb_recognition_dataset\")"
      ],
      "metadata": {
        "id": "wpm3bsLmpJ4M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colab_dir = '/content/wb_recognition_dataset/wb_recognition_dataset'\n",
        "dataset_dir = f'{colab_dir}'\n",
        "trainset_dir = f'{dataset_dir}/train'"
      ],
      "metadata": {
        "id": "ppiXjGnFpMEN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export augmented images with labels"
      ],
      "metadata": {
        "id": "GGwSevDyrTcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_handwriting_images(image_dir):\n",
        "    aug_name = [\"affine\" for _ in range(1)] + [\"rotate\" for _ in range(1)] + [\"elastic\" for _ in range(1)] + [\"perspective\" for _ in range(1)]\n",
        "\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")) and not filename.startswith((\"affine\", \"rotate\", \"elastic\", \"perspective\")):\n",
        "            image_path = os.path.join(image_dir, filename)\n",
        "            img = Image.open(image_path)\n",
        "\n",
        "            img_width, img_height = img.size\n",
        "\n",
        "            # pad with white pixels if image not square\n",
        "            if img_width <= 20 or img_height <= 20:\n",
        "              img = v2.Resize(size=(32,32))(img)\n",
        "\n",
        "            # random affine transform with rotation = (-20,20), translation = (0,0.1), scale = (0.95,1)\n",
        "            affine_transfomer = v2.RandomAffine(degrees=(-20, 20), translate=(0, 0.1), scale=(0.95, 1), fill=255)\n",
        "            affine_imgs = [affine_transfomer(img) for _ in range(1)]\n",
        "\n",
        "            # random rotation with angle = (-10,10)\n",
        "            rotater = v2.RandomRotation(degrees=(-10, 10), fill=255)\n",
        "            rotated_imgs = [rotater(img) for _ in range(1)]\n",
        "\n",
        "            # random elastic transformation with alpha = 75\n",
        "            elastic_transformer = v2.ElasticTransform(fill=255, alpha=75)\n",
        "            transformed_imgs = [elastic_transformer(img) for _ in range(1)]\n",
        "\n",
        "            # random perspective transformatioon with distortion = 0.5, p = 1\n",
        "            perspective_transformer = v2.RandomPerspective(distortion_scale=0.5, p=1, fill=255)\n",
        "            perspective_imgs = [perspective_transformer(img) for _ in range(1)]\n",
        "\n",
        "            aug_imgs = affine_imgs + rotated_imgs + transformed_imgs + perspective_imgs\n",
        "\n",
        "            for i, aug_img in enumerate(aug_imgs):\n",
        "                # name the augmented images with corresponding label and a random number\n",
        "                new_filename = f\"{aug_name[i]}_{random.randint(1000, 9999)}_{os.path.splitext(filename)[0]}{os.path.splitext(filename)[1]}\"\n",
        "                # save the augmented images to the same folder with the original image\n",
        "                aug_img.save(os.path.join(image_dir, new_filename))"
      ],
      "metadata": {
        "id": "1J7if7XhpRiI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for subdir in os.listdir(trainset_dir):\n",
        "    augment_handwriting_images(os.path.join(trainset_dir, subdir))"
      ],
      "metadata": {
        "id": "udzDqqN4pstn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}